# Deep Learning: Transfer Learning with Tensorflow

# step 1: import libraries
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# import dataset
dataset_path = "/usr/src/cookies"

# training dataset
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 20% validation
    horizontal_flip=True,
    rotation_range=30,
)

train_dataset = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=8,
    subset='training',
    class_mode='binary',
    classes=['good_cookies', 'bad_cookies']
)

val_dataset = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=8,
    subset='validation',
    class_mode='binary',
    classes=['good_cookies', 'bad_cookies']
)

# test dataset
test_dataset = val_dataset

# set performance parameter
AUTOTUNE = tf.data.AUTOTUNE

# import pretrained MobileNetv2 CNN
# set training to 0 for all layers
# do not retrain this network, use feature extraction
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
)

base_model.trainable = False

# add classification layer to top of network
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1, activation='sigmoid')
])

# compile and train model
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10
)

# step 10: review training statistics (accuracy and validation accuracy) and results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.legend()
plt.title('Loss')

plt.show()

# step 11: fine-tune the top 100 layers of MobileNetv2 to get better accuracy if needed.
# NOTE: if accuracy is below (80%, include fine-tuning in step 1)
# Unfreeze the top layers of the MobileNetV2 model for fine-tuning
base_model.trainable = True

# Freeze all layers except the top 100
for layer in base_model.layers[:-100]:
    layer.trainable = False

# Compile the model with a lower learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Fine-tune the model
history_fine = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10
)

# Plot fine-tuning results
acc_fine = history_fine.history['accuracy']
val_acc_fine = history_fine.history['val_accuracy']
loss_fine = history_fine.history['loss']
val_loss_fine = history_fine.history['val_loss']

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc_fine, label='Fine-Tuning Training Accuracy')
plt.plot(epochs, val_acc_fine, label='Fine-Tuning Validation Accuracy')
plt.legend()
plt.title('Fine-Tuning Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs, loss_fine, label='Fine-Tuning Training Loss')
plt.plot(epochs, val_loss_fine, label='Fine-Tuning Validation Loss')
plt.legend()
plt.title('Fine-Tuning Loss')

plt.show()

# Generate predictions on validation data
y_pred = model.predict(val_dataset)
y_pred_classes = (y_pred > 0.5).astype("int32").flatten()  # Convert sigmoid output to binary classes

# True labels
true_classes = val_dataset.classes

# Confusion matrix
cm = confusion_matrix(true_classes, y_pred_classes)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Classification report
print(classification_report(true_classes, y_pred_classes, target_names=val_dataset.class_indices.keys()))

